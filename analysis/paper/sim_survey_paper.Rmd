---
title: Using simulation to optimize the sampling design of fisheries-independent trawl surveys
author: "Paul M. Regular, Fran Mowbray, et al.?"
date: "Fisheries and Oceans Canada, Northwest Atlantic Fisheries Center, 80 East White Hills, St. John's, Newfoundland and Labrador, A1C 5X1, Canada"
output: 
  word_document:
    reference_docx: template.docx
bibliography: references.bib
csl: ices-journal-of-marine-science.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

A central question to fish stock assessments is: how many samples are needed to adequately represent the population being monitored? For assessments based on trawl surveys, our ability to estimate population characteristics, such as abundance at age, is affected by multiple levels of sampling (i.e. the number of sets, lengths and ages sampled in a survey). We therefore need to assess the impact of haul design and length and age sampling on survey accuracy to determine optimal sampling effort. In this study we simulated repeated stratified-random samples from a spatially correlated field of simulated fish. These samples were then analyzed and estimates of abundance at age were compared against a known truth. By varying the sampling protocol, we demonstrate that increasing the number of sets conducted per stratum provides the greatest gains in precision when sampling a clustered population. Increasing length and age sampling efforts also improved abundance estimates, but to a lesser extent. These results indicate that length and age sampling efforts for some species(e.g. cod *Gadus morhua*) in the trawl survey conducted by regional fisheries management organizations can be scaled back without significant losses to precision. Time saved by reducing said sampling may afford more time to conduct additional sets and/or increase sampling efforts of other species. While this simulation is tailored to a specific case, the method may be adapted to different systems and survey procedures.

**Keywords** - length and age distribution; simulation; spatial correlation; stratified analysis; statistical assessment models; survey design

# Introduction

Fisheries-independent trawl surveys have become an increasingly important research tool for the management of dynamic fish stocks. These surveys provide reliable indices of population abundance as well as estimates of various population characteristics such as length and age frequencies [@Pennington1998]. While costly to obtain, this information forms the basis of of many stock assessments models used throughout the world. Effective and informed management decisions therefore require surveys that maximize information while minimizing the expense of data collection. Determining the number of samples required to adequately characterize a fish population is particularly challenging since data tend to be collected across one or more stages [@Aanes2015]. Optimal survey design is further complicated by the fact that trawls sample clusters of fish that tend to have similar characteristics, such as length, age and stomach contents. This phenomenon results in samples with positive intra-haul correlation, which can markedly reduce the effective sample size for estimating length and age frequencies of the target population [@Pennington1994; @Pennington2002; @Stewart2014]. The complexities of multi-stage sampling and intra-haul correlation make it difficult to answer the question *"how much sampling is enough?"*  

Two main approaches have been applied to try and answer this question: one involves statistical estimators of effective sample size [@Pennington2002; @Stewart2014], and the other employs resampling methods to test alternate sampling protocol [@Cervino2006; @Zhang2013]. Both approaches have shown that lengths are usually oversampled and a reduction in said sampling can often be done without significant loss of accuracy [@Pennington2002]. The same result holds for other positively correlated characteristics, such as age [@Coggins2013] and stomach contents [@Bogstad1995]. Pennington and VÃ¸lstad [-@Pennington1994] concluded that the best way to improve the accuracy of surveys with strong intra-haul correlation is to take fewer samples per sampling unit and increase the total number of sampling locations. Few studies, however, have tested these conclusions using simulations. A key advantage of a pure simulation approach is that "true" population size and all stages of sampling can be controlled (set, length and age sampling protocol). The relative effects of each stage of sampling on our perception of the "truth" can then be tested. This level of testing is of particular importance for age composition estimates, and the contemporary age-based assessment models that rely on these estimates, as they are affected by all stages of sampling. A key challenge, of course, is building a simulation that emulates reality.  

The objective of this paper is to use a realistic simulation to evaluate the efficacy of various sampling protocol. First we simulated a spatially autocorrelated target population, and then we simulated surveys over this field. Set density was varied across surveys, as was length and age sampling efforts. Estimates of abundance at age were then obtained using a standard stratified approach [@Smith1981] and deviation from the truth was assessed. Given previous findings, we predict that the greatest gains in precision will come from increasing the number of hauls; increased sampling of correlated variables (length and age) on a set by set basis will be relatively ineffective. The bottom trawl survey of cod (*Gadus morhua*) in NAFO division 3Ps, Newfoundland, was used as a case study for this analysis.  

# Methods

The simulation presented here starts with a common cohort model where the abundance at age $a$ in year $y$ ($N_{a,y}$) equals the abundance of that cohort in the previous year multiplied by the survival rate, which is expressed in terms of total mortality ($Z_{a,y}$):
$$N_{a,y} = N_{a-1,y-1} e^{-Z_{a-1,y-1}}$$
Here, numbers-at-age in the first year are filled via exponential decay, $N_{a,1} = N_{a-1,1} e^{-Z_{a-1,1}}$, numbers at age 1 (i.e. recruits) are filled using a random walk, $log(N_{1,y}) = log(N_{1,y-1}) + \epsilon_{y-1}$, and total mortality is set to a baseline level plus process error, $log(Z_{a,y}) = log(z) + \delta_{a,y}$. The error around the recruitment process was simulated using the normal distribution, $\epsilon_{y} \sim N(0, \sigma_{r}^{2})$, and the process error was simulated using the covariance structure described in Cadigan [-@Cadigan2016]
$$\begin{eqnarray}
Cov(\delta_{a,y}, \delta_{a-i,y-j}) &=& \frac{\sigma_{\delta}^2 \varphi_{\delta, age}^i \varphi_{\delta, year}^j}{(1 - \varphi_{\delta, age}^2)(1 - \varphi_{\delta, year}^2)} \\
Corr(\delta_{a,y}, \delta_{a-i,y-j}) &=& \varphi_{\delta, age}^i \varphi_{\delta, year}^j
\end{eqnarray}
$$

This structure allows for autocorrelation in process errors over ages and years (i.e. total mortality can be made to be more similar for fish that are closer together in age and time). Overall, this  formulation allows for the simulation of an array of population dynamics that one might expect to observe.





# Acknowledgements

- Feedback and advice: Alejandro Buren, Mariano Koen-Alonso, Karen Dwyer, Joanne Morgan, Geoff Evans, Don Power, Brian Healey, Martha Robertson, Danny Ings, Don Stansbury, Mark Simpson, Derek Osborne, Peter Upward, Brad Squires, Dwayne Pittman, Paul Higdon
- Dave Cote for a review of a pervious version of this manuscript

# References


